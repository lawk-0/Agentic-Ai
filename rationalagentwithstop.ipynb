{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80a8d53-ed52-4f4c-ad0d-c34a52b9b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Simulation...\n",
      "\n",
      "--- Step 1 ---\n",
      "Percept: ('A', 'dirty')\n",
      "Action: Suck\n",
      "Environment: Location=A, A=clean, B=dirty\n",
      "Reward this step: 10\n",
      "Total Reward: 10\n",
      "Agent Internal State: {'A': 'dirty', 'B': 'unknown'}\n",
      "\n",
      "--- Step 2 ---\n",
      "Percept: ('A', 'clean')\n",
      "Action: Right\n",
      "Environment: Location=B, A=clean, B=dirty\n",
      "Reward this step: -1\n",
      "Total Reward: 9\n",
      "Agent Internal State: {'A': 'clean', 'B': 'unknown'}\n",
      "\n",
      "--- Step 3 ---\n",
      "Percept: ('B', 'dirty')\n",
      "Action: Suck\n",
      "Environment: Location=B, A=clean, B=clean\n",
      "Reward this step: 10\n",
      "Total Reward: 19\n",
      "Agent Internal State: {'A': 'clean', 'B': 'dirty'}\n",
      "\n",
      "--- Step 4 ---\n",
      "Percept: ('B', 'clean')\n",
      "Action: Stop\n",
      "Environment: Location=B, A=clean, B=clean\n",
      "Reward this step: 0\n",
      "Total Reward: 19\n",
      "Agent Internal State: {'A': 'clean', 'B': 'clean'}\n",
      "\n",
      "Agent decided to stop.\n",
      "Simulation Complete.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# ----------------------------\n",
    "# Environment\n",
    "# ----------------------------\n",
    "class VacuumEnvironment:\n",
    "    def __init__(self):\n",
    "        self.world = {\"A\": \"dirty\", \"B\": \"dirty\"}\n",
    "        self.location = \"A\"\n",
    "\n",
    "    def percept(self):\n",
    "        return (self.location, self.world[self.location])\n",
    "\n",
    "    def execute(self, action):\n",
    "        reward = 0\n",
    "        \n",
    "        if action == \"Suck\":\n",
    "            if self.world[self.location] == \"dirty\":\n",
    "                if random.random() < 0.8:\n",
    "                    self.world[self.location] = \"clean\"\n",
    "                    reward = 10\n",
    "                else:\n",
    "                    reward = 0\n",
    "            else:\n",
    "                reward = -2\n",
    "\n",
    "        elif action == \"Right\":\n",
    "            self.location = \"B\"\n",
    "            reward = -1\n",
    "            \n",
    "        elif action == \"Left\":\n",
    "            self.location = \"A\"\n",
    "            reward = -1\n",
    "\n",
    "        elif action == \"Stop\":\n",
    "            reward = 0\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"Environment: Location={self.location}, A={self.world['A']}, B={self.world['B']}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Rational Agent (One-step reward evaluation)\n",
    "# ----------------------------\n",
    "class VacuumAgent:\n",
    "    def __init__(self):\n",
    "        self.internal_state = {\"A\": \"unknown\", \"B\": \"unknown\"}\n",
    "        self.location = \"A\"\n",
    "        self.total_reward = 0\n",
    "\n",
    "    def update(self, percept):\n",
    "        location, dirt = percept\n",
    "        self.location = location\n",
    "        self.internal_state[location] = dirt\n",
    "\n",
    "    def choose_action(self):\n",
    "        # If current square dirty → best immediate reward\n",
    "        if self.internal_state[self.location] == \"dirty\":\n",
    "            return \"Suck\"\n",
    "\n",
    "        # If both squares are clean → Stop (avoid movement penalty)\n",
    "        if self.internal_state[\"A\"] == \"clean\" and self.internal_state[\"B\"] == \"clean\":\n",
    "            return \"Stop\"\n",
    "\n",
    "        # Otherwise move to other square\n",
    "        if self.location == \"A\":\n",
    "            return \"Right\"\n",
    "        return \"Left\"\n",
    "\n",
    "    def add_reward(self, reward):\n",
    "        self.total_reward += reward\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Simulation\n",
    "# ----------------------------\n",
    "env = VacuumEnvironment()\n",
    "agent = VacuumAgent()\n",
    "\n",
    "steps = 12\n",
    "\n",
    "print(\"Starting Simulation...\\n\")\n",
    "\n",
    "for step in range(steps):\n",
    "    print(f\"--- Step {step+1} ---\")\n",
    "    \n",
    "    percept = env.percept()\n",
    "    print(\"Percept:\", percept)\n",
    "    \n",
    "    agent.update(percept)\n",
    "    \n",
    "    action = agent.choose_action()\n",
    "    print(\"Action:\", action)\n",
    "    \n",
    "    reward = env.execute(action)\n",
    "    agent.add_reward(reward)\n",
    "    \n",
    "    env.show()\n",
    "    print(\"Reward this step:\", reward)\n",
    "    print(\"Total Reward:\", agent.total_reward)\n",
    "    print(\"Agent Internal State:\", agent.internal_state)\n",
    "    print()\n",
    "\n",
    "    if action == \"Stop\":\n",
    "        print(\"Agent decided to stop.\")\n",
    "        break\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"Simulation Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbb700-ca6e-4a99-83f5-2966a691af9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (virtual_env1)",
   "language": "python",
   "name": "virtual_env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
